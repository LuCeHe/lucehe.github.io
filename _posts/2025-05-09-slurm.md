---
layout: post
title: Supercomputers made easy
published: true
comments: true
---

Tired of the mess of writing submission scripts for big super computers? Now we are two. Wait no more.
I've created the [slurm-emission](https://github.com/LuCeHe/slurm-emission) package only for you, to make your life easier when you most need it: when you need to run experiments on a supercomputer. 
It allows you to focus on your favorite part, the Python code, so you don't need to worry about the SLURM details. In this post, I will show you how to use it.

### Intro

Most clusters are managed with SLURM, a package that takes care of organizing servers with many nodes, and users that are submitting jobs randomly. 

To be able to focus on the SLURM details, I’m going to assume i) you know how to create a GitHub repository for your project, ii) your main script is called `main.py`, and iii) you know how to use conda to create an environment, that we will refer to as my_env. You can use the repo https://github.com/LuCeHe/nice_repo_name if you wanna do some tests quickly.

### Entry, Interactive and Submission
In a cluster we usually have 3 modes of access: entry node, interactive mode and job submission. As soon as we get inside the server we will be in the entry node, but we will be restricted in the amount of resources, so we will be able to do only basic stuff there. If you want to test if your code runs properly with a small model and a few data samples on a GPU, you want to use the interactive mode. To access interactive mode use the salloc command

```salloc --partition only-one-gpu --account e.johnsson --gres=gpu:1```

Whenever you feel your code is fine and does not make errors, you are ready to launch a job. For that you need to create an .sh file and use the sbatch command. In the .sh file you specify the resources you need, the commands that need to be run before your code and the command to run your code. It will look as follows:

```
#!/bin/bash
#SBATCH --time=23:00:00
#SBATCH --account=e.johnsson
#SBATCH --partition=only-one-gpu
#SBATCH --gres=gpu:1

module load amd/slurm; module load amd/gcc-8.5.0/miniforge3
source activate base; conda activate my_env
cd /home/e.johnsson/work/nice_repo_name
python main.py
```

If you save it as my_sbatch.sh, then you submit the job with the command

```sbatch my_sbatch.sh```

That will put your job in line, and it will be run as the resources are freed.

### Automate .sh creation

As you see creating an .sh file for each submission can be annoying, so some automation that allows you to work only on Python could be interesting. To do that you can install

```pip install slurm-emission```


and write inside a `submit.py` file the following

```python
from slurm_emission import run_experiments

script_path = 'path/to/your/script'
script_name = 'script.py'

sbatch_args = {
    'partition': 'only-one-gpu',
    'gres': 'gpu:1',
    'account': 'e.johnsson',
    'time': '23:00:00',
}

id = 'llms'

experiments = [{
    'seed': list(range(4)), 'epochs': [300],
    'model': ['transformer', 'lstm'], 'dataset': ['cifar', 'mnist']
}]



load_modules = 'module load amd/slurm; module load amd/gcc-8.5.0/miniforge3'
activate_env = 'source activate base; conda activate my_env'
py_location = f'cd {script_path}'
bash_prelines = f'{load_modules}\n{activate_env}\n{py_location}'

run_experiments(
    experiments,
    init_command=f'python {script_name} ',
    sbatch_args=sbatch_args,
    bash_prelines=bash_prelines,
    id=id,
)
```

This python will create the exact same .sh as we did together manually, but on its own, and it will reuse it for the 16 possible combinations of datasets, models and seeds.

Now it’s on your plate, give it a try ;)



{% if page.comments %} 



<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://https-lucehe-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



{% endif %}
